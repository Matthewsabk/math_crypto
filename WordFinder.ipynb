{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a separated python file for the task of separating strings of letters all smashed together without spaces in to words and testing those words for sentence structures. It is an ongoing project and useful tool in conjunction with the Math_crypto lessons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from primePy import primes as pr\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_string = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "#the alphabet by positional index as a dictionary {index: letter}\n",
    "numeric_alphabet = {}\n",
    "#the alphabet as a dictionary {letter:index}\n",
    "alphabet_numeric = {}\n",
    "for n in range (0,26):\n",
    "    numeric_alphabet[n] = alphabet_string[n]\n",
    "    alphabet_numeric[alphabet_string[n]] = n\n",
    "# a list of the 1000 most common english language words from https://xkcd.com/simplewriter/words.js\n",
    "with open ('top1000words.txt') as file:\n",
    "    words_list = [word for line in file for word in line.split(\"|\")]\n",
    "words_list.append('a')\n",
    "words_list.append('i')\n",
    "words_list.append('test')\n",
    "words_list.append('strung')\n",
    "words_list.append('separated')\n",
    "words_list.append('secrets')\n",
    "words_list.append('shall')\n",
    "words_list.append('billboard')\n",
    "words_list.append('think')\n",
    "#print (words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_finder (some_string):\n",
    "    message = []\n",
    "    message_words = {}\n",
    "    strings_to_check = {}\n",
    "    fragments_to_check = {}\n",
    "    print(len(some_string))\n",
    "    #this loop sets up strings to check at each index - the potential start to each word.\n",
    "    for index in range (0, len(some_string)):\n",
    "        strings_to_check[index] = some_string[index: len(some_string)]\n",
    "        for index in strings_to_check.keys():\n",
    "            fragments_at_index =[]\n",
    "            for word_length in range (14,0, -1):\n",
    "                possible_fragment_word = strings_to_check[index][0: word_length]\n",
    "                fragments_at_index.append(possible_fragment_word)\n",
    "                fragments_to_check [index] = fragments_at_index\n",
    "    #this finds all the words at each potential index, descending order of length\n",
    "    for index in fragments_to_check.keys():\n",
    "        words_at_index = []\n",
    "        for fragment in fragments_to_check[index]:\n",
    "            if fragment in words_list:\n",
    "                words_at_index.append(fragment)\n",
    "                continue\n",
    "            message_words[index]= words_at_index\n",
    "    print(message_words)\n",
    "    #This loop checks to see if there's a word at the next block for each length of word in the words at potential indices. If there's a not a word, then it moves to the next smaller word.\n",
    "    message_index = -1\n",
    "    letter_count=0\n",
    "    for index in message_words.keys():\n",
    "        #print('index = ' +str(index))\n",
    "        #print('message_index = '+str(message_index))\n",
    "        if letter_count == len(some_string):\n",
    "            break\n",
    "        if letter_count > index:\n",
    "            continue\n",
    "        for word in message_words[index]:\n",
    "            print('index = ' +str(index))\n",
    "            print(word)\n",
    "            if index+len(word) >= len (message_words):\n",
    "                if message_words[index] != message[-1]:\n",
    "                    message.append(message_words[index][0])\n",
    "                    letter_count+=len(word)\n",
    "                    print('letter_count = '+ str(letter_count))\n",
    "                    break\n",
    "                break\n",
    "            if message_words[index+len(word)] != []:\n",
    "                message_index += len(word)\n",
    "                message.append (word)\n",
    "                letter_count+= len(word)\n",
    "                print('letter_count = '+ str(letter_count))\n",
    "                break\n",
    "    message_as_string = ' '. join(message)        \n",
    "    return(message_as_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first example encountered the problem of a too small corpus of words. The corpus of the most used 1000 words didn't include I, a, test, strung, or separated. I manually added those words to the word list and it was able to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "{0: ['this'], 1: ['his', 'hi'], 2: ['is', 'i'], 3: [], 4: ['is', 'i'], 5: ['sat'], 6: ['ate', 'at', 'a'], 7: ['test'], 8: [], 9: [], 10: ['to'], 11: ['of'], 12: ['fall'], 13: ['all', 'a'], 14: [], 15: [], 16: ['the'], 17: ['he'], 18: [], 19: ['words', 'word'], 20: ['or'], 21: [], 22: [], 23: [], 24: ['strung'], 25: [], 26: ['rung', 'run'], 27: [], 28: [], 29: [], 30: ['together', 'to'], 31: [], 32: ['get'], 33: [], 34: ['the'], 35: ['her', 'he'], 36: [], 37: [], 38: ['to'], 39: [], 40: ['be'], 41: [], 42: ['separated'], 43: [], 44: [], 45: ['a'], 46: [], 47: ['ate', 'at', 'a'], 48: [], 49: [], 50: [], 51: ['into', 'in', 'i'], 52: [], 53: ['top', 'to'], 54: [], 55: ['pieces', 'pieces', 'pieces', 'pieces', 'pieces', 'pieces', 'pieces', 'pieces', 'pieces', 'piece'], 56: ['i'], 57: [], 58: [], 59: [], 60: []}\n",
      "index = 0\n",
      "this\n",
      "letter_count = 4\n",
      "index = 1\n",
      "index = 2\n",
      "index = 3\n",
      "index = 4\n",
      "is\n",
      "letter_count = 6\n",
      "index = 5\n",
      "index = 6\n",
      "ate\n",
      "at\n",
      "a\n",
      "letter_count = 7\n",
      "index = 7\n",
      "test\n",
      "letter_count = 11\n",
      "index = 8\n",
      "index = 9\n",
      "index = 10\n",
      "index = 11\n",
      "of\n",
      "letter_count = 13\n",
      "index = 12\n",
      "index = 13\n",
      "all\n",
      "letter_count = 16\n",
      "index = 14\n",
      "index = 15\n",
      "index = 16\n",
      "the\n",
      "letter_count = 19\n",
      "index = 17\n",
      "index = 18\n",
      "index = 19\n",
      "words\n",
      "letter_count = 24\n",
      "index = 20\n",
      "index = 21\n",
      "index = 22\n",
      "index = 23\n",
      "index = 24\n",
      "strung\n",
      "letter_count = 30\n",
      "index = 25\n",
      "index = 26\n",
      "index = 27\n",
      "index = 28\n",
      "index = 29\n",
      "index = 30\n",
      "together\n",
      "letter_count = 38\n",
      "index = 31\n",
      "index = 32\n",
      "index = 33\n",
      "index = 34\n",
      "index = 35\n",
      "index = 36\n",
      "index = 37\n",
      "index = 38\n",
      "to\n",
      "letter_count = 40\n",
      "index = 39\n",
      "index = 40\n",
      "be\n",
      "letter_count = 42\n",
      "index = 41\n",
      "index = 42\n",
      "separated\n",
      "letter_count = 51\n",
      "index = 43\n",
      "index = 44\n",
      "index = 45\n",
      "index = 46\n",
      "index = 47\n",
      "index = 48\n",
      "index = 49\n",
      "index = 50\n",
      "index = 51\n",
      "into\n",
      "letter_count = 55\n",
      "index = 52\n",
      "index = 53\n",
      "index = 54\n",
      "index = 55\n",
      "pieces\n",
      "letter_count = 61\n",
      "index = 56\n",
      "this is a test of all the words strung together to be separated into pieces\n"
     ]
    }
   ],
   "source": [
    "test_string = \"thisisatestofallthewordsstrungtogethertobeseparatedintopieces\"\n",
    "test_chunks_strings = word_finder(test_string)\n",
    "print (test_chunks_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are no secrets better than the secrets that everybody guesses\n"
     ]
    }
   ],
   "source": [
    "#that didn't work on the first example I tried. Why not? \n",
    "test2_string = \"therearenosecretsbetterthanthesecretsthateverybodyguesses\"\n",
    "testing_2 = word_finder(test2_string)\n",
    "print(testing_2)\n",
    "#Because the word \"secrets\" isn't in the top 1000 words list. I need to update the words library to a longer library for this to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "index = 0\n",
      "when\n",
      "letter_count = 3\n",
      "index = 1\n",
      "index = 2\n",
      "index = 3\n",
      "index = 4\n",
      "angry\n",
      "letter_count = 8\n",
      "index = 5\n",
      "index = 6\n",
      "index = 7\n",
      "index = 8\n",
      "index = 9\n",
      "count\n",
      "letter_count = 13\n",
      "index = 10\n",
      "index = 11\n",
      "index = 12\n",
      "index = 13\n",
      "index = 14\n",
      "ten\n",
      "letter_count = 16\n",
      "index = 15\n",
      "index = 16\n",
      "index = 17\n",
      "before\n",
      "letter_count = 22\n",
      "index = 18\n",
      "index = 19\n",
      "index = 20\n",
      "index = 21\n",
      "index = 22\n",
      "index = 23\n",
      "you\n",
      "letter_count = 25\n",
      "index = 24\n",
      "index = 25\n",
      "index = 26\n",
      "speak\n",
      "letter_count = 30\n",
      "index = 27\n",
      "index = 28\n",
      "index = 29\n",
      "index = 30\n",
      "index = 31\n",
      "if\n",
      "letter_count = 32\n",
      "index = 32\n",
      "index = 33\n",
      "very\n",
      "letter_count = 36\n",
      "index = 34\n",
      "index = 35\n",
      "index = 36\n",
      "index = 37\n",
      "angry\n",
      "letter_count = 41\n",
      "index = 38\n",
      "index = 39\n",
      "index = 40\n",
      "index = 41\n",
      "index = 42\n",
      "an\n",
      "letter_count = 43\n",
      "index = 43\n",
      "index = 44\n",
      "hundred\n",
      "letter_count = 50\n",
      "index = 45\n",
      "index = 46\n",
      "index = 47\n",
      "index = 48\n",
      "index = 49\n",
      "index = 50\n",
      "when angry count ten before you speak if very angry an hundred\n"
     ]
    }
   ],
   "source": [
    "#this one fails because it catches the word 'red' at the tail end of 'hundred'\n",
    "test3_string = \"whenangrycounttenbeforeyouspeakifveryangryanhundred\"\n",
    "testing_3 = word_finder(test3_string)\n",
    "print(testing_3)\n",
    "#the solution to was to establish a letter count such that they must total the number of letters in the original string and stop if it will exceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "{0: ['it', 'i'], 1: ['think', 'thin'], 2: ['hi'], 3: ['in', 'i'], 4: [], 5: [], 6: ['that'], 7: ['hat', 'ha'], 8: ['at', 'a'], 9: [], 10: ['is', 'i'], 11: ['shall'], 12: ['hall', 'ha'], 13: ['all', 'a'], 14: [], 15: [], 16: ['never'], 17: ['ever'], 18: [], 19: [], 20: [], 21: ['see'], 22: [], 23: [], 24: ['a'], 25: ['billboard'], 26: ['ill', 'i'], 27: [], 28: [], 29: ['board'], 30: [], 31: ['a'], 32: [], 33: [], 34: ['love'], 35: [], 36: [], 37: [], 38: [], 39: [], 40: ['as', 'a'], 41: ['sat'], 42: ['at', 'a'], 43: ['tree', 'tree', 'tree', 'tree', 'tree', 'tree', 'tree', 'tree', 'tree', 'tree', 'tree'], 44: [], 45: [], 46: []}\n",
      "index = 0\n",
      "it\n",
      "letter_count = 2\n",
      "index = 2\n",
      "hi\n",
      "index = 3\n",
      "in\n",
      "index = 3\n",
      "i\n",
      "index = 6\n",
      "that\n",
      "letter_count = 6\n",
      "index = 7\n",
      "hat\n",
      "letter_count = 9\n",
      "index = 10\n",
      "is\n",
      "letter_count = 11\n",
      "index = 11\n",
      "shall\n",
      "letter_count = 16\n",
      "index = 16\n",
      "never\n",
      "letter_count = 21\n",
      "index = 21\n",
      "see\n",
      "letter_count = 24\n",
      "index = 24\n",
      "a\n",
      "letter_count = 25\n",
      "index = 25\n",
      "billboard\n",
      "letter_count = 34\n",
      "index = 34\n",
      "love\n",
      "index = 40\n",
      "as\n",
      "letter_count = 36\n",
      "index = 41\n",
      "sat\n",
      "index = 42\n",
      "at\n",
      "index = 42\n",
      "a\n",
      "letter_count = 37\n",
      "index = 43\n",
      "tree\n",
      "letter_count = 41\n",
      "it that hat is shall never see a billboard as a tree\n"
     ]
    }
   ],
   "source": [
    "#this one fails because the first word it tests is 'it' instead of 'i', then it finds 'hi' at index 2 instead of 'think' at index 1.\n",
    "#using the letter count added above, it should be possible to \n",
    "test4_string = \"ithinkthatishallneverseeabillboardlovelyasatree\"\n",
    "testing_4 = word_finder(test4_string)\n",
    "print(testing_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
